{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6bb9a088-00be-4fa3-a299-95f38547f5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install opencv-python --user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2209f41-8d9b-4ef4-8c8b-ed37eb8e78c2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9eae6fbf-8570-4c51-a8b7-036e930c65cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import sys\n",
    "import traceback\n",
    "\n",
    "\n",
    "class Counter():\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"TBD\"\"\"\n",
    "        \n",
    "        self.model = None\n",
    "        self.video_source_path = None\n",
    "        self.video_source_is_video = None\n",
    "        self.excercise_name = None\n",
    "        self.end_video_loop='q'\n",
    "        self.frame_count=0\n",
    "        self.counter=0\n",
    "        self.cap=None\n",
    "        self.frame=None\n",
    "        self.show_skeleton=False\n",
    "        self.model_type=None\n",
    "        \n",
    "        \n",
    "     \n",
    "  #########\n",
    "\n",
    "    def set_args(\n",
    "            self,\n",
    "            video_source_path=0.1,\n",
    "            video_source_is_video=False,\n",
    "            excercise_name=None, \n",
    "            show_skeleton=False,\n",
    "            model_type=None\n",
    "        ):\n",
    "            \"\"\"\n",
    "            Configure all objects\n",
    "\n",
    "            Args:\n",
    "                tbd\n",
    "            \"\"\"\n",
    "\n",
    "            self.video_source_path = video_source_path\n",
    "            self.video_source_is_video = video_source_is_video\n",
    "            self.excercise_name = excercise_name\n",
    "            self.show_skeleton=show_skeleton\n",
    "            self.model_type=model_type\n",
    "\n",
    "####\n",
    "        \n",
    "        \n",
    "\n",
    "    def run_model(self):\n",
    "        \n",
    "        if self.model_type.upper()=='N':\n",
    "            self.model=YOLO(\"yolov8n-pose.pt\")\n",
    "        elif self.model_type.upper()=='S':\n",
    "            self.model=YOLO(\"yolov8s-pose.pt\")\n",
    "        elif self.model_type.upper()=='M':\n",
    "            self.model=YOLO(\"yolov8m-pose.pt\")\n",
    "        else:\n",
    "            self.model=YOLO(\"yolov8n-pose.pt\")\n",
    "            \n",
    "        if self.video_source_is_video:\n",
    "            self.cap = cv2.VideoCapture(self.video_source_path)# path to video file or webcam (webcam==0)\n",
    "    \n",
    "        else:\n",
    "            self.cap = cv2.VideoCapture(0)# path to video file or webcam (webcam==0)\n",
    "        \n",
    "        gym_object = ExcerciseCounter()  # init Excercsie counter \n",
    "        gym_object.set_args(line_thickness=3,\n",
    "                    view_img=True,\n",
    "                    pose_type=self.excercise_name,\n",
    "                    video_source_is_video=self.video_source_is_video,\n",
    "                    show_skeleton=self.show_skeleton\n",
    "                           )\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        assert self.cap.isOpened(), \"Error reading video file\"\n",
    "        w, h, fps = (int(self.cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))\n",
    "\n",
    "        if not self.cap.isOpened():\n",
    "            print(\"Error reading video file\")\n",
    "            sys.exit()\n",
    "        try:\n",
    "            while self.cap.isOpened() :\n",
    "                success, frame = self.cap.read()\n",
    "                self.frame=frame\n",
    "                #frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                \n",
    "                self.frame.flags.writeable = False\n",
    "                \n",
    "                if not success: #or (frame_count % process_every_n_frames != 0 and frame_count>1):\n",
    "                    print(\"Video frame is empty or video processing has been successfully completed.\")\n",
    "                    break\n",
    "\n",
    "\n",
    "                results = self.model.predict(self.frame, verbose=False) ##predicts people including all boxes,etc\n",
    "\n",
    "                #print(f\"keypoints len: {results[0].keypoints.data}\")\n",
    "                if results[0].keypoints.data.numel()==0:\n",
    "                    print(\"No perosn detected\")\n",
    "                    continue\n",
    "\n",
    "                #print(results[0])\n",
    "                #print(results[0].names)\n",
    "                self.frame.flags.writeable = True\n",
    "                #print(\"Start Counting\")\n",
    "                self.frame_count+=1\n",
    "\n",
    "\n",
    "\n",
    "                self.frame = gym_object.start_counting(self.frame, results, self.frame_count)\n",
    "\n",
    "                self.frame = cv2.resize(self.frame, (640, 640), interpolation = cv2.INTER_AREA)\n",
    "                cv2.imshow(\"Excercise counter active\", self.frame)\n",
    "\n",
    "\n",
    "                if cv2.waitKey(1) & 0xFF == ord(self.end_video_loop):\n",
    "                    break\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {traceback.format_exc()}\")\n",
    "\n",
    "        finally:\n",
    "            self.cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9998dc33-e862-40dd-b9b6-4b69006ed746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is not available. Running on CPU.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available. GPU acceleration can be used.\")\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    print(\"CUDA is not available. Running on CPU.\")\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e347a0-7a34-4b7e-9849-f6e16c66c3bc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Annotator Subclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "50d6eb30-724f-41d0-bf82-51f365cd932b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics.utils.plotting import Annotator\n",
    "import numpy as np\n",
    "\n",
    "class Annotator_altered(Annotator):\n",
    "    def __init__(self, im0,  *args, **kwargs): #Annotator(im0, line_width=2)\n",
    "        super().__init__(im0,  *args, **kwargs)  # Call the constructor of the base class (if needed)\n",
    "        #print(\"Subclass constructor called.\")\n",
    "        #print(self.im0)\n",
    "  \n",
    "\n",
    "    \n",
    "    def draw_specific_points(self, keypoints, indices=[2, 5, 7], shape=(640, 640), radius=2):\n",
    "        \"\"\"\n",
    "        Draw specific keypoints for gym steps counting.\n",
    "\n",
    "        Args:\n",
    "            keypoints (list): list of keypoints data to be plotted (required)\n",
    "            indices (list): keypoints ids list to be plotted\n",
    "            shape (tuple): imgsz for model inference\n",
    "            radius (int): Keypoint radius value\n",
    "        \"\"\"\n",
    "        for i, k in enumerate(keypoints):\n",
    "           \n",
    "            #if i in indices:\n",
    "            x_coord, y_coord = k[0], k[1]\n",
    "            if x_coord % shape[1] != 0 and y_coord % shape[0] != 0:\n",
    "                if len(k) == 3:\n",
    "                    conf = k[2]\n",
    "                    if conf < 0.5: ## confidence value (if smaller skipp)\n",
    "                        continue\n",
    "                cv2.circle(self.im, (int(x_coord), int(y_coord)), radius, (0, 255, 0), -1, lineType=cv2.LINE_AA)\n",
    "        return self.im\n",
    "    \n",
    "    \n",
    "    def plot_angle_and_count_and_stage(self, angle_text, count_text, stage_text, center_kpt, line_thickness=2,n_people=1,video_source_is_video=True):\n",
    "        \"\"\"  \n",
    "        Plot the pose angle, count value and step stage.\n",
    "\n",
    "        Args:\n",
    "            angle_text (str): angle value for workout monitoring (required)\n",
    "            count_text (str): counts value for workout monitoring (required)\n",
    "            stage_text (str): stage decision for workout monitoring (required)\n",
    "            center_kpt (int): centroid pose index for workout monitoring (required)\n",
    "            line_thickness (int): thickness for text display\n",
    "        \"\"\"\n",
    "        angle_text, count_text, stage_text = (f\" {angle_text:.0f}\", f\"Count : {count_text}\", f\" {stage_text}\")\n",
    "        \n",
    "        if n_people>1:\n",
    "             extra_scale=n_people+1\n",
    "        else:\n",
    "            extra_scale=n_people\n",
    "        \n",
    "        if video_source_is_video==False:\n",
    "            extra_scale=n_people+4\n",
    "        \n",
    "        font_scale = (5 + (line_thickness / 10.0))/extra_scale ##befroe it was 10\n",
    "        draw_angle=False\n",
    "\n",
    "        \n",
    "            \n",
    "        \n",
    "        # Draw angle\n",
    "        (angle_text_width, angle_text_height), _ = cv2.getTextSize(angle_text, 0, font_scale, line_thickness)\n",
    "        #angle_text_position = (int(center_kpt[0]), int(center_kpt[1])) #tuple(np.multiply(elbow_r, [640, 480]).astype(int)) (maybe use this to adjust to output frame size)\n",
    "        #print(center_kpt, self.im.shape[0],self.im.shape[1])\n",
    "        angle_text_position = (int(center_kpt[0]), int(center_kpt[1])) #tuple(np.multiply(elbow_r, [640, 480]).astype(int)) (maybe use this to adjust to output frame size)\n",
    "\n",
    "        angle_background_position = (angle_text_position[0], angle_text_position[1] - angle_text_height - 5)\n",
    "        angle_background_size = (angle_text_width + 2 * 5, angle_text_height + 2 * 5 + (line_thickness * 2))\n",
    "        \n",
    "        if draw_angle:\n",
    "            cv2.rectangle(\n",
    "                self.im,\n",
    "                angle_background_position,\n",
    "                (\n",
    "                    angle_background_position[0] + angle_background_size[0],\n",
    "                    angle_background_position[1] + angle_background_size[1],\n",
    "                ),\n",
    "                (255, 255, 255),\n",
    "                -1,\n",
    "            )\n",
    "            cv2.putText(self.im, angle_text, angle_text_position, 0, font_scale, (0, 0, 0), line_thickness)\n",
    "\n",
    "       \n",
    "        # Draw Counts\n",
    "        (count_text_width, count_text_height), _ = cv2.getTextSize(count_text, 0, font_scale, line_thickness)\n",
    "        count_text_position = (angle_text_position[0], angle_text_position[1] + angle_text_height + 10)\n",
    "        \n",
    "        count_background_position = (\n",
    "            angle_background_position[0],\n",
    "            angle_background_position[1] + angle_background_size[1] + 5,\n",
    "        )  ## before 10,10\n",
    "        count_background_size = (count_text_width + 3, count_text_height + 2 + (line_thickness * 1))\n",
    "\n",
    "        cv2.rectangle(\n",
    "            self.im,\n",
    "            count_background_position,\n",
    "            (\n",
    "                count_background_position[0] + count_background_size[0],\n",
    "                count_background_position[1] + count_background_size[1],\n",
    "            ),\n",
    "            (255, 255, 255),\n",
    "            -1,\n",
    "        )\n",
    "        cv2.putText(self.im, count_text, count_text_position, 0, font_scale, (0, 0, 0), line_thickness)\n",
    "\n",
    "        # Draw Stage\n",
    "        (stage_text_width, stage_text_height), _ = cv2.getTextSize(stage_text, 0, font_scale, line_thickness)\n",
    "        stage_text_position = (int(center_kpt[0]), int(center_kpt[1]) + angle_text_height + count_text_height + 40)\n",
    "        stage_background_position = (stage_text_position[0], stage_text_position[1] - stage_text_height - 5)\n",
    "        \n",
    "        ##befroe 10,10\n",
    "        stage_background_size = (stage_text_width + 3, stage_text_height + 5)\n",
    "\n",
    "        cv2.rectangle(\n",
    "            self.im,\n",
    "            stage_background_position,\n",
    "            (\n",
    "                stage_background_position[0] + stage_background_size[0],\n",
    "                stage_background_position[1] + stage_background_size[1],\n",
    "            ),\n",
    "            (255, 255, 255),\n",
    "            -1,\n",
    "        )\n",
    "        cv2.putText(self.im, stage_text, stage_text_position, 0, font_scale, (0, 0, 0), line_thickness)\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5db5f0-529d-4bcf-bde7-ca259965b581",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Excercise class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9d2b37e1-8c3c-4be3-88a4-9b36541d6fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://docs.ultralytics.com/guides/workouts-monitoring/#real-world-applications\n",
    "#https://github.com/ultralytics/ultralytics/blob/main/ultralytics/solutions/ai_gym.py\n",
    "\n",
    "from ultralytics.utils.checks import check_imshow\n",
    "from ultralytics.utils.plotting import Annotator\n",
    "\n",
    "class ExcerciseCounter:\n",
    "    \"\"\" class to manage multi-person excercise counting.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Initializes the class with default vals.\"\"\"\n",
    "\n",
    "        # Image and line thickness\n",
    "        self.im0 = None\n",
    "        self.tf = None\n",
    "        self.show_skeleton=False\n",
    "\n",
    "        # Keypoints and count information\n",
    "        self.keypoints = None\n",
    "        self.poseup_angle = None\n",
    "        self.posedown_angle = None\n",
    "        self.threshold = 0.001\n",
    "        self.upperbody_angle=None\n",
    "        self.n_people=None\n",
    "\n",
    "        # Store stage, count and angle information\n",
    "        self.angle_r = None #added\n",
    "        self.angle_l = None #added\n",
    "        self.angle_upperbody_l=None\n",
    "        self.angle_upperbody_r=None\n",
    "        self.count = None\n",
    "        self.stage = None\n",
    "        self.pose_type = None\n",
    "     \n",
    "\n",
    "        # Visual Information\n",
    "        self.view_img = False\n",
    "        self.annotator = None\n",
    "        self.video_source_is_video=None\n",
    "\n",
    "        # Check if environment support imshow\n",
    "        self.env_check = check_imshow(warn=True)\n",
    "\n",
    "    def set_args(\n",
    "        self,\n",
    "        line_thickness=0.1,\n",
    "        view_img=False,\n",
    "        pose_type=None, \n",
    "        video_source_is_video=False,\n",
    "        show_skeleton=False,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Configures the line_thickness, save image and view image parameters.\n",
    "\n",
    "        Args:\n",
    "            kpts_to_check (list): 3 keypoints for counting\n",
    "            line_thickness (int): Line thickness for bounding boxes.\n",
    "            view_img (bool): display the im0\n",
    "            pose_up_angle (float): Angle to set pose position up\n",
    "            pose_down_angle (float): Angle to set pose position down\n",
    "            pose_type (str): \"pushup\", \"pullup\" or \"abworkout\"\n",
    "        \"\"\"\n",
    "      \n",
    "        self.tf = line_thickness\n",
    "        self.view_img = view_img\n",
    "        self.pose_type = pose_type\n",
    "        self.video_source_is_video=video_source_is_video\n",
    "        self.show_skeleton=show_skeleton\n",
    "        \n",
    "\n",
    "    \n",
    "    def start_counting(self, im0, results, frame_count):\n",
    "        \"\"\"\n",
    "        Function used to count excercsie.\n",
    "\n",
    "        Args:\n",
    "            im0 (ndarray): Current frame from the video stream.\n",
    "            results (list): Pose estimation data\n",
    "            frame_count (int): store current frame count\n",
    "        \"\"\"\n",
    "        self.im0 = im0\n",
    "        \n",
    "        ## if this is the first frame then initialize the objects (counter,angles,stages) with their respective lengths\n",
    "        if frame_count == 1:\n",
    "            self.count = [0] * len(results[0])\n",
    "            self.angle_r = [0] * len(results[0]) #added\n",
    "            self.angle_l = [0] * len(results[0]) #added\n",
    "            self.angle_upperbody_l=[0] * len(results[0]) #added\n",
    "            self.angle_upperbody_r=[0] * len(results[0]) #added\n",
    "            self.stage = [\"-\" for _ in results[0]]  ## for each element (name is irrelevant thats why _ ) \n",
    "        self.keypoints = results[0].keypoints.data\n",
    "        self.annotator = Annotator_altered(im0, line_width=1)  ### to write on image (image and width of the writing)\n",
    "       \n",
    "        num_keypoints = len(results[0]) ## amount of people working out  \n",
    "        self.n_people=num_keypoints\n",
    "        #print(f\"# people identified: {num_keypoints}\")\n",
    "        \n",
    "        # Resize self.angle, self.count, and self.stage if the number of keypoints has changed\n",
    "        if len(self.angle_r) != num_keypoints:\n",
    "            self.angle_r = [0] * num_keypoints\n",
    "            self.angle_l = [0] * num_keypoints\n",
    "            self.angle_upperbody_l=[0] * num_keypoints\n",
    "            self.angle_upperbody_r=[0] * num_keypoints\n",
    "            self.count = [0] * num_keypoints\n",
    "            self.stage = [\"-\" for _ in range(num_keypoints)]\n",
    "\n",
    "    \n",
    "        \n",
    "        if self.pose_type==\"pushup\":\n",
    "            self.push_up_excercise()\n",
    "        \n",
    "        if self.pose_type==\"pullup\":\n",
    "            #ex=Excercise(im0,self.keypoints,self.annotator)\n",
    "            self.pull_up_excercise()\n",
    "        \n",
    "        if self.pose_type==\"crunch\":\n",
    "            self.crunch_excercise()\n",
    "      \n",
    "        if self.pose_type==\"benchpress\":\n",
    "            print(\"test\")\n",
    "            \n",
    "        if self.pose_type==\"triceps_curl\":\n",
    "            print(\"test\")\n",
    "        \n",
    "        if self.pose_type==\"biceps_curl\":\n",
    "            print(\"test\")\n",
    "        \n",
    "        if self.pose_type==\"squad\":\n",
    "            self.squad_excercise()\n",
    "\n",
    "        return self.im0\n",
    "\n",
    "    \n",
    "    \n",
    "    def map_keypoint_to_body_part(self,k):\n",
    "        \n",
    "        body_part=['nose', 'eye_l', 'eye_r', 'ear_l', 'ear_r', 'shoulder_l', 'shoulder_r',\n",
    "                   'elbow_l', 'elbow_r', 'wrist_l', 'wrist_r', 'hip_l', 'hip_r', 'knee_l','knee_r', 'ankle_l', 'ankle_r']\n",
    "        keypoints_index= {var: i for i, var in enumerate(body_part)}\n",
    "        keypoints_values_map = {var: k[i] for i, var in enumerate(body_part)}\n",
    "        \n",
    "        \n",
    " \n",
    "        return keypoints_values_map,keypoints_index\n",
    "    \n",
    "    \n",
    "    \n",
    "    def pull_up_excercise(self):\n",
    "        \n",
    "        \n",
    "        ### Set thresholds \n",
    "        self.poseup_angle=70,\n",
    "        self.posedown_angle=140\n",
    "        \n",
    "        angle_keypoints_l=[\"shoulder_l\",\"elbow_l\",\"wrist_l\"]\n",
    "        angle_keypoints_r=[\"shoulder_r\",\"elbow_r\",\"wrist_r\"]\n",
    "        \n",
    "        \n",
    "        \n",
    "        for ind, k in enumerate(reversed(self.keypoints)):\n",
    "            \n",
    "            body_parts,body_parts_index=self.map_keypoint_to_body_part(k)\n",
    "            \n",
    "            #self.im0 = self.annotator.draw_specific_points(k, shape=(640*0.5, 640*0.5), radius=1)\n",
    "            #self.im0 = self.annotator.draw_specific_points(k, shape=(640*0.5, 640*0.5), radius=1)\n",
    "            \n",
    "            self.kpts_to_check_l=[body_parts_index.get(item, None) for item in angle_keypoints_l]   \n",
    "            self.kpts_to_check_r=[body_parts_index.get(item, None) for item in angle_keypoints_r]  \n",
    "\n",
    "            \n",
    "            ### Measure angles             \n",
    "            self.angle_l[ind] = self.annotator.estimate_pose_angle(\n",
    "                body_parts[angle_keypoints_l[0]].cpu(),  ## erster Keypoint \n",
    "                body_parts[angle_keypoints_l[1]].cpu(),  ## zweiter keypoint bsp. elbow\n",
    "                body_parts[angle_keypoints_l[2]].cpu(), ## 3ter keypoints bspw. shoulder \n",
    "                )\n",
    "\n",
    "            self.angle_r[ind] = self.annotator.estimate_pose_angle(\n",
    "               body_parts[angle_keypoints_r[0]].cpu(),  ## erster Keypoint \n",
    "                body_parts[angle_keypoints_r[1]].cpu(),  ## zweiter keypoint bsp. elbow\n",
    "                body_parts[angle_keypoints_r[2]].cpu(), ## 3ter keypoints bspw. shoulder \n",
    "                )\n",
    "\n",
    "\n",
    " \n",
    "            ## Define conditions for states and counts\n",
    "            #print(f\"ind: {ind} ,stage: {self.stage[ind]}\")\n",
    "            condition_down_1= self.angle_l[ind] > self.posedown_angle and self.angle_r[ind] > self.posedown_angle\n",
    "            condition_down_2= body_parts['wrist_l'][1].cpu()<body_parts['shoulder_l'][1].cpu() and body_parts['wrist_r'][1].cpu()<body_parts['shoulder_r'][1].cpu()\n",
    "            \n",
    "            condition_up_1= self.angle_l[ind] < self.poseup_angle and self.angle_r[ind] < self.poseup_angle\n",
    "            condition_up_2= body_parts['nose'][1].cpu()<body_parts['wrist_l'][1].cpu() and body_parts['nose'][1].cpu()<body_parts['wrist_r'][1].cpu()\n",
    "            condition_up_3= self.stage[ind] == \"down\"\n",
    "\n",
    "            ### Test conditions \n",
    "            if condition_down_1 and condition_down_2 :\n",
    "                self.stage[ind] = \"down\"\n",
    "                           \n",
    "            if condition_up_1 and condition_up_2 and condition_up_3 :\n",
    "                self.stage[ind] = \"up\"\n",
    "                self.count[ind] += 1\n",
    "                           \n",
    "\n",
    "            self.annotator.plot_angle_and_count_and_stage(\n",
    "                angle_text=self.angle_l[ind],\n",
    "                count_text=self.count[ind],\n",
    "                stage_text=self.stage[ind],\n",
    "                center_kpt=k[0],\n",
    "                line_thickness=self.tf,\n",
    "                n_people=self.n_people,\n",
    "                video_source_is_video=self.video_source_is_video,\n",
    "                )\n",
    "            \n",
    "            if self.show_skeleton:\n",
    "                self.annotator.kpts(k, shape=(640, 640), radius=1, kpt_line=True)\n",
    "    \n",
    "\n",
    "    def push_up_excercise(self):\n",
    "             \n",
    "        ### Set thresholds \n",
    "        self.poseup_angle=140,\n",
    "        self.posedown_angle=100\n",
    "        self.upperbody_angle=120\n",
    "        \n",
    "        angle_keypoints_l=[\"shoulder_l\",\"elbow_l\",\"wrist_l\"]\n",
    "        angle_keypoints_r=[\"shoulder_r\",\"elbow_r\",\"wrist_r\"]\n",
    "        angle_keypoints_upper_body_r=[\"ankle_r\",\"hip_r\",\"nose\"]\n",
    "        angle_keypoints_upper_body_l=[\"ankle_l\",\"hip_l\",\"nose\"]\n",
    "        \n",
    "        \n",
    "        for ind, k in enumerate(reversed(self.keypoints)):\n",
    "            \n",
    "            body_parts,body_parts_index=self.map_keypoint_to_body_part(k)\n",
    "            \n",
    "            ### Measure angles \n",
    "            self.angle_l[ind] = self.annotator.estimate_pose_angle(\n",
    "                body_parts[angle_keypoints_l[0]].cpu(),  ## erster Keypoint \n",
    "                body_parts[angle_keypoints_l[1]].cpu(),  ## zweiter keypoint bsp. elbow\n",
    "                body_parts[angle_keypoints_l[2]].cpu(), ## 3ter keypoints bspw. shoulder \n",
    "                )\n",
    "\n",
    "            self.angle_r[ind] = self.annotator.estimate_pose_angle(\n",
    "               body_parts[angle_keypoints_r[0]].cpu(),  ## erster Keypoint \n",
    "                body_parts[angle_keypoints_r[1]].cpu(),  ## zweiter keypoint bsp. elbow\n",
    "                body_parts[angle_keypoints_r[2]].cpu(), ## 3ter keypoints bspw. shoulder \n",
    "                )\n",
    "\n",
    "            self.angle_upperbody_r[ind] = self.annotator.estimate_pose_angle(\n",
    "               body_parts[angle_keypoints_upper_body_r[0]].cpu(),  ## erster Keypoint \n",
    "                body_parts[angle_keypoints_upper_body_r[1]].cpu(),  ## zweiter keypoint bsp. elbow\n",
    "                body_parts[angle_keypoints_upper_body_r[2]].cpu(), ## 3ter keypoints bspw. shoulder \n",
    "                )\n",
    "            \n",
    "            self.angle_upperbody_l[ind] = self.annotator.estimate_pose_angle(\n",
    "               body_parts[angle_keypoints_upper_body_l[0]].cpu(),  ## erster Keypoint \n",
    "                body_parts[angle_keypoints_upper_body_l[1]].cpu(),  ## zweiter keypoint bsp. elbow\n",
    "                body_parts[angle_keypoints_upper_body_l[2]].cpu(), ## 3ter keypoints bspw. shoulder \n",
    "                )\n",
    "\n",
    "            ## Define conditions for states and counts\n",
    "            condition_up_1= self.angle_l[ind] > self.poseup_angle or self.angle_r[ind] > self.poseup_angle\n",
    "            condition_up_2= self.angle_upperbody_l[ind]> self.upperbody_angle or self.angle_upperbody_r[ind]> self.upperbody_angle\n",
    "            \n",
    "            condition_down_1= self.angle_l[ind] < self.posedown_angle or self.angle_r[ind] < self.posedown_angle\n",
    "            condition_down_2= self.angle_upperbody_l[ind]> self.upperbody_angle or self.angle_upperbody_r[ind]> self.upperbody_angle\n",
    "            condition_down_3= self.stage[ind] == \"up\"\n",
    "                        \n",
    "            print(f\"{self.angle_l[ind]},{self.angle_r[ind]},{self.stage[ind]}\")\n",
    "            ### Test conditions \n",
    "            if condition_up_1 and condition_up_2 :\n",
    "                self.stage[ind] = \"up\"\n",
    "                            #if ind ==1:\n",
    "                                #print(\"down\")\n",
    "            if condition_down_1 and condition_down_2 and condition_down_3 :\n",
    "                self.stage[ind] = \"down\"\n",
    "                self.count[ind] += 1\n",
    "                          \n",
    "\n",
    "            #print(self.video_source_is_video)\n",
    "            self.annotator.plot_angle_and_count_and_stage(\n",
    "                angle_text=self.angle_l[ind],\n",
    "                count_text=self.count[ind],\n",
    "                stage_text=self.stage[ind],\n",
    "                center_kpt=k[0],\n",
    "                line_thickness=self.tf,\n",
    "                n_people=self.n_people,\n",
    "                video_source_is_video=self.video_source_is_video,\n",
    "                )\n",
    "            \n",
    "            if self.show_skeleton:\n",
    "                self.annotator.kpts(k, shape=(640, 640), radius=1, kpt_line=True)\n",
    "            \n",
    "\n",
    "    def to_implement_excercise(self):\n",
    "             \n",
    "        ### Set thresholds \n",
    "        self.poseup_angle=140,\n",
    "        self.posedown_angle=60\n",
    "        self.upperbody_angle=120\n",
    "        \n",
    "        angle_keypoints_l=[\"shoulder_l\",\"elbow_l\",\"wrist_l\"]\n",
    "        angle_keypoints_r=[\"shoulder_r\",\"elbow_r\",\"wrist_r\"]\n",
    "        angle_keypoints_upper_body_r=[\"ankle_r\",\"hip_r\",\"nose\"]\n",
    "        angle_keypoints_upper_body_l=[\"ankle_l\",\"hip_l\",\"nose\"]\n",
    "        \n",
    "        \n",
    "        for ind, k in enumerate(reversed(self.keypoints)):\n",
    "            \n",
    "            body_parts,body_parts_index=self.map_keypoint_to_body_part(k)\n",
    "            \n",
    "            \n",
    "            ### Measure angles \n",
    "            self.angle_l[ind] = self.annotator.estimate_pose_angle(\n",
    "                body_parts[angle_keypoints_l[0]].cpu(),  ## erster Keypoint \n",
    "                body_parts[angle_keypoints_l[1]].cpu(),  ## zweiter keypoint bsp. elbow\n",
    "                body_parts[angle_keypoints_l[2]].cpu(), ## 3ter keypoints bspw. shoulder \n",
    "                )\n",
    "\n",
    "            self.angle_r[ind] = self.annotator.estimate_pose_angle(\n",
    "               body_parts[angle_keypoints_r[0]].cpu(),  ## erster Keypoint \n",
    "                body_parts[angle_keypoints_r[1]].cpu(),  ## zweiter keypoint bsp. elbow\n",
    "                body_parts[angle_keypoints_r[2]].cpu(), ## 3ter keypoints bspw. shoulder \n",
    "                )\n",
    "\n",
    "            \n",
    "            self.angle_upperbody_r[ind] = self.annotator.estimate_pose_angle(\n",
    "               body_parts[angle_keypoints_upper_body_r[0]].cpu(),  ## erster Keypoint \n",
    "                body_parts[angle_keypoints_upper_body_r[1]].cpu(),  ## zweiter keypoint bsp. elbow\n",
    "                body_parts[angle_keypoints_upper_body_r[2]].cpu(), ## 3ter keypoints bspw. shoulder \n",
    "                )\n",
    "            \n",
    "            self.angle_upperbody_l[ind] = self.annotator.estimate_pose_angle(\n",
    "               body_parts[angle_keypoints_upper_body_l[0]].cpu(),  ## erster Keypoint \n",
    "                body_parts[angle_keypoints_upper_body_l[1]].cpu(),  ## zweiter keypoint bsp. elbow\n",
    "                body_parts[angle_keypoints_upper_body_l[2]].cpu(), ## 3ter keypoints bspw. shoulder \n",
    "                )\n",
    "\n",
    "        \n",
    "            \n",
    "            ## Define conditions for states and counts\n",
    "            condition_up_1= self.angle_l[ind] > self.poseup_angle or self.angle_r[ind] > self.poseup_angle\n",
    "            condition_up_2= self.angle_upperbody_l[ind]> self.upperbody_angle or self.angle_upperbody_r[ind]> self.upperbody_angle\n",
    "            \n",
    "            condition_down_1= self.angle_l[ind] < self.posedown_angle or self.angle_r[ind] < self.posedown_angle\n",
    "            condition_down_2= self.angle_upperbody_l[ind]> self.upperbody_angle or self.angle_upperbody_r[ind]> self.upperbody_angle\n",
    "            condition_down_3= self.stage[ind] == \"up\"\n",
    "          \n",
    "            ### Test conditions \n",
    "            if condition_up_1 and condition_up_2 :\n",
    "                self.stage[ind] = \"up\"\n",
    "                           \n",
    "            if condition_down_1 and condition_down_2 and condition_down_3 :\n",
    "                self.stage[ind] = \"down\"\n",
    "                self.count[ind] += 1\n",
    "                          \n",
    "\n",
    "            self.annotator.plot_angle_and_count_and_stage(\n",
    "                angle_text=self.angle_l[ind],\n",
    "                count_text=self.count[ind],\n",
    "                stage_text=self.stage[ind],\n",
    "                center_kpt=k[0],\n",
    "                line_thickness=self.tf,\n",
    "                )\n",
    "            if self.show_skeleton:\n",
    "                self.annotator.kpts(k, shape=(640, 640), radius=1, kpt_line=True)\n",
    "            \n",
    "            \n",
    "    def crunch_excercise(self):\n",
    "             \n",
    "        ### Set thresholds \n",
    "        self.poseup_angle=110,\n",
    "        self.posedown_angle=130\n",
    "       \n",
    "        angle_keypoints_l=[\"knee_l\",\"hip_l\",\"shoulder_l\"]\n",
    "        angle_keypoints_r=[\"knee_r\",\"hip_r\",\"shoulder_r\"]\n",
    "        \n",
    "        \n",
    "        for ind, k in enumerate(reversed(self.keypoints)):\n",
    "            \n",
    "            body_parts,body_parts_index=self.map_keypoint_to_body_part(k)\n",
    "            \n",
    "            \n",
    "            ### Measure angles \n",
    "            self.angle_l[ind] = self.annotator.estimate_pose_angle(\n",
    "                body_parts[angle_keypoints_l[0]].cpu(),  ## erster Keypoint \n",
    "                body_parts[angle_keypoints_l[1]].cpu(),  ## zweiter keypoint bsp. elbow\n",
    "                body_parts[angle_keypoints_l[2]].cpu(), ## 3ter keypoints bspw. shoulder \n",
    "                )\n",
    "\n",
    "            self.angle_r[ind] = self.annotator.estimate_pose_angle(\n",
    "               body_parts[angle_keypoints_r[0]].cpu(),  ## erster Keypoint \n",
    "                body_parts[angle_keypoints_r[1]].cpu(),  ## zweiter keypoint bsp. elbow\n",
    "                body_parts[angle_keypoints_r[2]].cpu(), ## 3ter keypoints bspw. shoulder \n",
    "                )\n",
    "\n",
    "            \n",
    "            ## Define conditions for states and counts\n",
    "            condition_up_1= self.angle_l[ind] < self.poseup_angle or self.angle_r[ind] < self.poseup_angle\n",
    "            condition_up_2= self.stage[ind] == \"down\"\n",
    "            \n",
    "            condition_down_1= self.angle_l[ind] > self.posedown_angle or self.angle_r[ind] > self.posedown_angle\n",
    "           \n",
    "            #print( self.angle_l[ind], self.angle_r[ind])\n",
    "            \n",
    "            \n",
    "            ### Test conditions\n",
    "            #print(f\"{self.angle_l[ind]},{self.angle_r[ind]},{self.stage[ind]}\")\n",
    "            \n",
    "            if condition_up_1 and condition_up_2 :\n",
    "                self.stage[ind] = \"up\"\n",
    "                self.count[ind] += 1\n",
    "                print(f\"count post: {self.count[ind]}\")\n",
    "                           \n",
    "            if condition_down_1:\n",
    "                self.stage[ind] = \"down\"\n",
    "                \n",
    "                          \n",
    "\n",
    "            self.annotator.plot_angle_and_count_and_stage(\n",
    "                angle_text=self.angle_l[ind],\n",
    "                count_text=self.count[ind],\n",
    "                stage_text=self.stage[ind],\n",
    "                center_kpt=k[0],\n",
    "                line_thickness=self.tf,\n",
    "                n_people=self.n_people,\n",
    "                video_source_is_video=self.video_source_is_video,\n",
    "                )\n",
    "            if self.show_skeleton:\n",
    "                self.annotator.kpts(k, shape=(640, 640), radius=1, kpt_line=True)\n",
    "            \n",
    "            \n",
    "    \n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "#    ExcerciseCounter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "14c0ab8e-83fc-49e1-9e4e-a49e27fca2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_model=Counter()\n",
    "\n",
    "counter_model.set_args(video_source_path=None,\n",
    "                    video_source_is_video=False,\n",
    "                    excercise_name='pullup',\n",
    "                    show_skeleton=True,\n",
    "                    model_type='s')\n",
    "\n",
    "counter_model.run_model()\n",
    "\n",
    "\n",
    "#'Copy of C1_PullUp_short.mp4' 'pullup'\n",
    "#'crunch_3.mp4'  'crunch'\n",
    "\n",
    "#'Push_Up.mp4' 'pushup'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc-showcode": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
